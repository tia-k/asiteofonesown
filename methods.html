<!DOCTYPE html>
<html>
    <head>
        <title>A (Short) Study in Sherlock - The Method</title>
        <link rel="stylesheet" type="text/css" href="styles.css" />
        <link rel="icon" type="image/x-icon" href="icons8-cube-24.png" />
    </head>
    <body>
        <div class="container">
            <div class="top">
                <h1>A (Short) Study in Sherlock</h1>
                <p>A little website, for the purpose of a concise exercise in the digital humanities.</p>
                <p><a href="./">[index]</a> <b><a href="./methods">[methodology]</a></b> <a href="./python">[python code]</a></p>
            </div>
            <div class="main">
                <div class="authorsnote">
                    <p><i>Author's note: This website runs best in Chrome on a desktop or laptop PC. The author has made every effort to ensure the site runs, but, if it fails to, a version in a word document is provided.</i></p>
                </div>
                <div class="essay">
                    <h2>Methodology and Notes</h2>
                    <h3>Notes on my methods</h3>
                    <ul>
                        <li>I undertook type-token analysis by repurposing the word counting code we worked on in class, and storing values to calculate the ratio of unique words to total words in the text, which I have considered here to be a proxy for overall lexical variation in a text.</li>
                        <li>"Sentiment" in sentiment analysis here refers to how "positive" or "negative" language is according to the crowdsourced database used by the Python version of the open-source <a href="https://github.com/cjhutto/vaderSentiment" target="_blank">VADER sentiment analysis tool</a>. For my analysis, I used VADER to find 'normalized, weighted and composite score[s]' for the texts' sentences, and then worked with these scores to calculate averages for sections of the texts I also used the <a href="https://www.nltk.org/" target="_blank">Natural Language Toolkit</a> for splitting texts into sentences.<span id="footnote_one_indic"><a href="#footnote_one">[1]</a></span></li>
                        <li>For the natural language processing section of my analysis, I used the <a href="https://spacy.io/" target="_blank">spaCy</a> module to recognise parts of speech.</li>
                        <li>I used <a href="https://pandas.pydata.org/" target="_blank">pandas</a> for turning data into dataframes (tables) and, in some instances, <a href="https://xlsxwriter.readthedocs.io/" target="_blank">xlsxwriter</a> to aid in writing data to .xlsx files.</li>
                    </ul>
                    <br>
                    <h3>Unused content</h3>
                    <p>
                        Throughout my undertaking of this project, several elements went unused. The network visualisations I created were the one element I elected not to use in the body analysis. In the initial phases, I created CSVs where explicit exchanges of dialogue were listed as connections and ran this data through Stanford's <a href="https://hdlab.stanford.edu/palladio/" target="_blank">Palladio</a> tool and <a href="https://networknavigator.jrladd.com/" target="_blank">Network Navigator</a> to create visualisations and gain numerical data about characters' centrality. Ultimately, I elected not to consider these visualisations in the main analysis, as they showed the obvious: Sherlock Holmes is central to the Sherlock Holmes series. Other unused data includes the data for TTR across individual short stories; while this data was generated and visualisations made (which can be seen in Excel files, which are available upon request), I could not make much sense of this data. The other major pieces of unused data were related to NLP. Parts-of-speech graphs for all parts-of-speech I considered were made, but due to time, only the graph displaying the relative uses of each type has been considered in the main analysis. In addition, I worked with some bigram data, as can be seen in the code, but the data found there could arguably form a project of its own, so it was not used here.<br><br>
                    </p>
                    <h3>Miscellaneous Notes</h3>
                    <p>
                       I have aimed to make my methods as easy to replicate as possible: scripts can be viewed in part on another page on this site, and the raw text for my corpus comes from the ever-useful <a href="https://www.gutenberg.org/">Project Gutenberg</a>. Though not all the data I have produced is viewable here or used in my analysis, all of it is available upon request. I have cleaned both the corpus data and my own produced data to some degree, but I fully acknowledge that my data has not been perfectly cleaned, mainly to get this project out on time. Nonetheless, I hope my data is clean enough, and my code well explained enough that the vision for this project is apparent, even if I have yet to achieve it in the most complete and elegant manner on my own. 
                    </p>
                </div>
                <div class="footnotes">
                    <ol>
                        <li id="footnote_one">cjHutto, ‘VaderSentiment Documentation’, <i><a href="https://github.com/cjhutto/vaderSentiment" target="_blank">VaderSentiment - GitHub</a></i> [accessed 16 December 2023].<a href="#footnote_one_indic">^</a></li>
                    </ol>
                    <ul>
                        <li><a target="_blank" href="https://icons8.com/icon/98119/cube">Cube</a> icon by <a target="_blank" href="https://icons8.com">Icons8</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </body>
</html>
