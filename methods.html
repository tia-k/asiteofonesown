<!DOCTYPE html>
<html>
    <head>
        <title>A (Short) Study in Sherlock - The Method</title>
        <link rel="stylesheet" type="text/css" href="styles.css" />
        <link rel="icon" type="image/x-icon" href="icons8-cube-24.png" />
    </head>
    <body>
        <div class="container">
            <div class="top">
                <h1>A (Short) Study in Sherlock</h1>
                <p>A little website, for the purpose of a concise exercise in the digital humanities.</p>
                <p><a href="./">[index]</a> <b><a href="./methods">[methodology]</a></b> <a href="./python">[python code]</a></p>
            </div>
            <div class="main">
                <div class="authorsnote">
                    <p><i>Author's note: This website is a very rough and ready project, because it feels far more in the spirit of the digital humanities than a word document. It runs best in Chrome on a desktop or laptop PC. The author has made every effort to ensure the site runs, but, if it fails to, a version in a word document is provided.</i></p>
                </div>
                <div class="essay">
                    <h2>methodology and notes.</h2>
                    <p>
                        To test my hypothesis that Arthur Conan Doyle developed a semantic and structural formula and applied it across the Sherlock Holmes series, both in the full-length novels and the short stories, I have undertaken four main methods, which I will explain here.<br><br>
                    </p>
                    <h3>1. Type-Token Analysis</h3>
                    <p>Type-token analysis refers to an attempt to measure the lexical variety of a text by comparing the number of unique words it contains (types) to the total amount of words it contains (tokens). The type-token ratio, abbreviated as TTR, the ratio of types to tokens. I have represented this as a number between zero and one, calculated by dividing the number of types by the number of tokens. This value can act as a proxy for lexical variety: a TTR of one is the most variety possible, a TTR of zero is the least variety possible. <br><br>
                    </p>
                    <h3>2. Sentiment Analysis</h3>
                    <p>
                        When I refer to "sentiment" here, it refers to how "positive" or "negative" the language of a text or section of a text is. I have performed sentiment analysis using the Python version of the open-source <a href="https://github.com/cjhutto/vaderSentiment" target="_blank">VADER sentiment analysis tool</a>. VADER's database consists of individual words, rated as positive or negative on a scale from -4 to +4, as gathered through crowdsourcing. The sentiment analyser tool can apply these ratings to each word in a sentence and calculate a 'normalized, weighted, composite score' for a pre-determined section's sentiment on a scale of -1 (the most negative) to +1 (the most positive). In my code, I have elected to do this analysis for each complete sentence in a text, and then take averages for each five-per cent of the text.<br><br>
                    </p>
                    <h3>3. Natural Language Processing and Parts-of-Speech</h3>
                    <p>
                        Here, Natural Language Processing refers to computational recognition of parts-of-speech such as verbs, nouns, and proper names. For my reading, I have used <a href="https://spacy.io/" target="_blank">spaCy</a> to recognise these parts-of-speech. Using spaCy, I processed each text to gather the words associated with different parts of speech, which I then used other Python modules to count.<br><br>
                    </p>
                    <h3>Unused content</h3>
                    <p>
                        Throughout my undertaking of this project, several elements went unused. The network visualisations I created were the one element I elected not to use in the body analysis. In the initial phases, I created CSVs where explicit exchanges of dialogue were listed as connections and ran this data through Stanford's <a href="https://hdlab.stanford.edu/palladio/" target="_blank">Palladio</a> tool and <a href="https://networknavigator.jrladd.com/" target="_blank">Network Navigator</a> to create visualisations and gain numerical data about characters' centrality. Ultimately, I elected not to consider these visualisations in the main analysis, as they showed the obvious: Sherlock Holmes is central to the Sherlock Holmes series. Other unused data includes the data for TTR across individual short stories; while this data was generated and visualisations made (which can be seen in Excel files, which are available upon request), I could not make much sense of this data. The other major pieces of unused data were related to NLP. Parts-of-speech graphs for all parts-of-speech I considered were made, but due to time, only the graph displaying the relative uses of each type has been considered in the main analysis. In addition, I worked with some bigram data, as can be seen in the code, but the data found there could arguably form a project of its own, so it was not used here.<br><br>
                    </p>
                    <h3>Miscellaneous Notes</h3>
                    <p>
                       I have aimed to make my methods as easy to replicate as possible: scripts can be viewed in part on another page on this site, and the raw text for my corpus comes from the ever-useful <a href="https://www.gutenberg.org/">Project Gutenberg</a>. Though not all the data I have produced is viewable here or used in my analysis, all of it is available upon request. I have cleaned both the corpus data and my own produced data to some degree, but I fully acknowledge that my data has not been perfectly cleaned, mainly to get this project out on time. Nonetheless, I hope my data is clean enough, and my code well explained enough that the vision for this project is apparent, even if I have yet to achieve it in the most complete and elegant manner on my own. 
                    </p>
                </div>
                <div class="footnotes">
                    <ol>
                        <li id="footnote_one">cjHutto, ‘VaderSentiment Documentation’, <i><a href="https://github.com/cjhutto/vaderSentiment" target="_blank">VaderSentiment - GitHub</a></i> [accessed 16 December 2023].<a href="#footnote_one_indic">^</a></li>
                    </ol>
                    <ul>
                        <li><a target="_blank" href="https://icons8.com/icon/98119/cube">Cube</a> icon by <a target="_blank" href="https://icons8.com">Icons8</a></li>
                    </ul>
                </div>
            </div>
        </div>
    </body>
</html>
